{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 2\n",
    "import numpy as np\n",
    "actions = {'north':(-1,0), 'south':(1,0), 'west':(0,-1), 'east':(0,1)}\n",
    "N = 5\n",
    "A = (0,1)\n",
    "B = (0,3)\n",
    "gamma = 0.9\n",
    "\n",
    "# For a given (s,a) pair the s_d, and reward r is fixed\n",
    "def find(s, a):\n",
    "    if s == A:\n",
    "        s_d, r = (4,1), 10\n",
    "        return (s_d, r)\n",
    "    if s == B:\n",
    "        s_d, r = (2,3), 5\n",
    "        return (s_d, r)\n",
    "    x, y = s\n",
    "    dx, dy = actions[a]\n",
    "    x = x + dx\n",
    "    y = y + dy\n",
    "    r = 0\n",
    "    if y<0:\n",
    "        y = 0\n",
    "        r = -1\n",
    "    if y>=N:\n",
    "        y = N-1\n",
    "        r = -1\n",
    "    if x<0:\n",
    "        x = 0\n",
    "        r = -1\n",
    "    if x>=N:\n",
    "        x = N-1\n",
    "        r = -1\n",
    "    s_d = (x,y)\n",
    "    return (s_d, r)\n",
    "\n",
    "def mdp(s_d, r, s, a):\n",
    "    s_e, r_e = find(s,a)\n",
    "    if s_d == s_e and r == r_e:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def E(s, V, pi):\n",
    "    v = 0\n",
    "    for a in actions:\n",
    "        s_d, r = find(s, a)\n",
    "        v += pi[(s, a)]*(r + gamma*V[s_d])\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For evaluating V_pi Policy Evaluation is used\n",
    "rewards = [[0.0 for i in range(N)] for j in range(N)]\n",
    "V = {}\n",
    "states = []\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        s = (i,j)\n",
    "        states.append(s)\n",
    "        V[s] = 0.0\n",
    "        \n",
    "pi = {}\n",
    "for i in states:\n",
    "    for j in actions:\n",
    "        pi[(i,j)] = 0.25\n",
    "\n",
    "epsilon = 0.0001\n",
    "\n",
    "def policy_eval(V, pi):\n",
    "    ## Policy Evaluation\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            v = V[s]\n",
    "            V[s] = E(s,V,pi)\n",
    "            delta = max(delta, abs(v-V[s]))\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_upd(V, pi):\n",
    "    ## Policy update\n",
    "    f = True\n",
    "    for s in states:\n",
    "        old_a = None\n",
    "        for a in actions:\n",
    "            if pi[(s,a)] == 1:\n",
    "                old_a = a\n",
    "        if old_a == None:\n",
    "            old_a = 'nan'\n",
    "        a_given_s = None\n",
    "        m = -1e9\n",
    "        for a in actions:\n",
    "            s_d, r = find(s, a)\n",
    "            if r + gamma*V[s_d] > m:\n",
    "                m = r + gamma*V[s_d]\n",
    "                a_given_s = a\n",
    "                \n",
    "        for a in actions:\n",
    "            pi[(s,a)] = 0\n",
    "\n",
    "        pi[(s,a_given_s)] = 1.0\n",
    "        if a_given_s != old_a:\n",
    "            f = False\n",
    "    return (pi, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.3  8.8  4.4  5.3  1.5]\n",
      " [ 1.5  3.   2.3  1.9  0.5]\n",
      " [ 0.1  0.7  0.7  0.4 -0.4]\n",
      " [-1.  -0.4 -0.4 -0.6 -1.2]\n",
      " [-1.9 -1.3 -1.2 -1.4 -2. ]]\n"
     ]
    }
   ],
   "source": [
    "## V is computed using policy evaluation for the given policy pi\n",
    "V = policy_eval(V,pi)\n",
    "for i in V:\n",
    "    x, y = i\n",
    "    rewards[x][y] = round(V[i],1)\n",
    "\n",
    "rewards = np.array(rewards)\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 4\n",
    "def policy_iteration(V, pi):\n",
    "    ## Initialisation\n",
    "    V = {}\n",
    "    states = []\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            s = (i,j)\n",
    "            states.append(s)\n",
    "            V[s] = 0.0\n",
    "\n",
    "    pi = {}\n",
    "    for i in states:\n",
    "        for j in actions:\n",
    "            pi[(i,j)] = 0.25\n",
    "    f = False\n",
    "    iter = 1\n",
    "    ## The Program is bound to terminate as the policy update step deterministically picks the first action that maximuise q(s,a)\n",
    "    while not f:\n",
    "        print(\"Iteration:\",iter)\n",
    "        V = policy_eval(V, pi)\n",
    "        pi, f = policy_upd(V, pi)\n",
    "        iter += 1\n",
    "    return (V, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n"
     ]
    }
   ],
   "source": [
    "V, pi = policy_iteration(V, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0 24.4 22.0 19.4 17.5\n",
      "19.8 22.0 19.8 17.8 16.0\n",
      "17.8 19.8 17.8 16.0 14.4\n",
      "16.0 17.8 16.0 14.4 13.0\n",
      "14.4 16.0 14.4 13.0 11.7\n",
      "Policy by Policy iter\n",
      "[['east' 'north' 'west' 'north' 'west']\n",
      " ['east' 'north' 'north' 'west' 'west']\n",
      " ['east' 'north' 'north' 'north' 'north']\n",
      " ['east' 'north' 'north' 'north' 'north']\n",
      " ['east' 'north' 'north' 'north' 'north']]\n",
      "Updated Policy\n",
      "[['east' 'any' 'west' 'any' 'west']\n",
      " ['east' 'north' 'north' 'west' 'west']\n",
      " ['east' 'north' 'north' 'north' 'north']\n",
      " ['east' 'north' 'north' 'north' 'north']\n",
      " ['east' 'north' 'north' 'north' 'north']]\n"
     ]
    }
   ],
   "source": [
    "for i in V:\n",
    "    x, y = i\n",
    "    rewards[x][y] = round(V[i],1)\n",
    "    \n",
    "for i in range(N):\n",
    "    print(*rewards[i])\n",
    "    \n",
    "policy = [['' for i in range(N)] for j in range(N)]\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        if pi[(s,a)] == 1.0:\n",
    "            policy[s[0]][s[1]] = a\n",
    "            \n",
    "## Policy by Policy iter\n",
    "policy = np.array(policy)\n",
    "print(\"Policy by Policy iter\")\n",
    "print(policy)\n",
    "\n",
    "## Since we know moves in A and B are independent and move to A' and B', we can set it to any\n",
    "policy[A[0]][A[1]] = 'any'\n",
    "policy[B[0]][B[1]] = 'any'\n",
    "## Updated Policy\n",
    "print(\"Updated Policy\")\n",
    "policy = np.array(policy)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration:\n",
      "Iteration: 1\n",
      "[0.0, -0.2, -0.3, -0.4]\n",
      "[-0.2, -0.3, -0.4, -0.2]\n",
      "[-0.3, -0.3, -0.2, -0.2]\n",
      "[-0.3, -0.3, -0.8, 0.0]\n",
      "Iteration: 2\n",
      "[0.0, -1.0, -1.3, -1.2]\n",
      "[-1.0, -1.3, -1.2, -1.2]\n",
      "[-1.3, -1.2, -1.2, -1.0]\n",
      "[-1.3, -1.3, -1.0, 0.0]\n",
      "Iteration: 3\n",
      "[0.0, -1.0, -2.0, -2.2]\n",
      "[-1.0, -2.0, -2.2, -2.0]\n",
      "[-2.0, -2.2, -2.0, -1.0]\n",
      "[-2.3, -2.0, -1.0, 0.0]\n",
      "Iteration: 4\n",
      "[0.0, -1.0, -2.0, -3.0]\n",
      "[-1.0, -2.0, -3.0, -2.0]\n",
      "[-2.0, -3.0, -2.0, -1.0]\n",
      "[-3.0, -2.0, -1.0, 0.0]\n",
      "Iteration: 5\n",
      "[0.0, -1.0, -2.0, -3.0]\n",
      "[-1.0, -2.0, -3.0, -2.0]\n",
      "[-2.0, -3.0, -2.0, -1.0]\n",
      "[-3.0, -2.0, -1.0, 0.0]\n",
      "\n",
      "Policy Iteration:\n",
      "Iteration: 1\n",
      "[0.0, -14.0, -20.0, -22.0]\n",
      "[-14.0, -18.0, -20.0, -20.0]\n",
      "[-20.0, -20.0, -18.0, -14.0]\n",
      "[-22.0, -20.0, -14.0, 0.0]\n",
      "\n",
      "['.', 'left', 'left', 'left']\n",
      "['up', 'up', 'left', 'down']\n",
      "['up', 'up', 'right', 'down']\n",
      "['up', 'right', 'right', '.']\n",
      "Iteration: 2\n",
      "[0.0, -1.0, -2.0, -3.0]\n",
      "[-1.0, -2.0, -3.0, -2.0]\n",
      "[-2.0, -3.0, -2.0, -1.0]\n",
      "[-3.0, -2.0, -1.0, 0.0]\n",
      "\n",
      "['.', 'left', 'left', 'down']\n",
      "['up', 'up', 'up', 'down']\n",
      "['up', 'up', 'down', 'down']\n",
      "['up', 'right', 'right', '.']\n",
      "Iteration: 3\n",
      "[0.0, -1.0, -2.0, -3.0]\n",
      "[-1.0, -2.0, -3.0, -2.0]\n",
      "[-2.0, -3.0, -2.0, -1.0]\n",
      "[-3.0, -2.0, -1.0, 0.0]\n",
      "\n",
      "['.', 'left', 'left', 'down']\n",
      "['up', 'up', 'up', 'down']\n",
      "['up', 'up', 'down', 'down']\n",
      "['up', 'right', 'right', '.']\n"
     ]
    }
   ],
   "source": [
    "## Question 6\n",
    "\n",
    "def show(V, pi, iteration):\n",
    "    print(iteration)\n",
    "    for i in V:\n",
    "        x, y = i\n",
    "        rewards[x][y] = round(V[i],1)\n",
    "\n",
    "    policy = [['' for i in range(N)] for j in range(N)]\n",
    "\n",
    "    for s in states:\n",
    "        for a in actions:\n",
    "            if pi[(s,a)] == 1:\n",
    "                policy[s[0]][s[1]] = a\n",
    "\n",
    "    policy[A[0]][A[1]] = \".\"\n",
    "    policy[B[0]][B[1]] = \".\"\n",
    "    for i in range(N):\n",
    "        print(rewards[i])\n",
    "    print()\n",
    "    for i in range(N):\n",
    "        print(policy[i])\n",
    "\n",
    "def show_value(V, iteration):\n",
    "    print(iteration)\n",
    "    for i in V:\n",
    "        x, y = i\n",
    "        rewards[x][y] = round(V[i],1)\n",
    "    for i in range(N):\n",
    "        print(rewards[i])\n",
    "    \n",
    "actions = {'up':(-1,0), 'down':(1,0), 'left':(0,-1), 'right':(0,1)}\n",
    "N = 4\n",
    "A = (0,0)\n",
    "B = (3,3)\n",
    "gamma = 1.0\n",
    "states = []\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        s = (i,j)\n",
    "        states.append(s)\n",
    "\n",
    "def find(s, a):\n",
    "    x, y = s\n",
    "    dx, dy = actions[a]\n",
    "    x = x + dx\n",
    "    y = y + dy\n",
    "    r = -1\n",
    "    if y<0:\n",
    "        y = 0\n",
    "    if y>=N:\n",
    "        y = N-1\n",
    "    if x<0:\n",
    "        x = 0\n",
    "    if x>=N:\n",
    "        x = N-1\n",
    "        \n",
    "    s_d = (x,y)\n",
    "    return (s_d, r)\n",
    "    \n",
    "rewards = [[0.0 for i in range(N)] for j in range(N)]\n",
    "epsilon = 0.001\n",
    "\n",
    "def E_max(s, V):\n",
    "    v = -1e9\n",
    "    for a in actions:\n",
    "        s_d, r = find(s, a)\n",
    "        v = max(v,(r + gamma*V[s_d]))\n",
    "    return v\n",
    "\n",
    "## Value iteration\n",
    "def update(V):\n",
    "    iter = 1\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            if s == A or s==B:\n",
    "                continue\n",
    "            v = V[s]\n",
    "            V[s] = E_max(s,V)\n",
    "            delta = max(delta, abs(v-V[s]))\n",
    "        itr = \"Iteration: \" + str(iter)\n",
    "        show_value(V, itr)\n",
    "        iter+=1\n",
    "        \n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_update(V, pi):\n",
    "    for s in states:\n",
    "        if s == A or s==B:\n",
    "            continue\n",
    "        a_given_s = None\n",
    "        m = -1e9\n",
    "        for a in actions:\n",
    "            s_d, r = find(s, a)\n",
    "            if r + gamma*V[s_d] > m:\n",
    "                m = r + gamma*V[s_d]\n",
    "                a_given_s = a\n",
    "                \n",
    "        for a in actions:\n",
    "            pi[(s,a)] = 0\n",
    "        pi[(s,a_given_s)] = 1.0\n",
    "    return pi\n",
    "\n",
    "import random\n",
    "def value_iteration():\n",
    "    print(\"Value Iteration:\")\n",
    "    V = {}\n",
    "    states = []\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            s = (i,j)\n",
    "            states.append(s)\n",
    "            V[s] = random.random()\n",
    "    V[A] = 0.0\n",
    "    V[B] = 0.0\n",
    "\n",
    "    pi = {}\n",
    "    for i in states:\n",
    "        for j in actions:\n",
    "            pi[(i,j)] = 0.25\n",
    "            \n",
    "    V = update(V)\n",
    "    pi = policy_update(V, pi)\n",
    "    return (V, pi)\n",
    "\n",
    "\n",
    "## Policy iteration\n",
    "epsilon = 0.0001\n",
    "def policy_eval(V, pi):\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            if s == A or s==B:\n",
    "                continue\n",
    "            v = V[s]\n",
    "            V[s] = E(s,V,pi)\n",
    "            delta = max(delta, abs(v-V[s]))\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_upd(V, pi):\n",
    "    f = True\n",
    "    for s in states:\n",
    "        old_a = None\n",
    "        for a in actions:\n",
    "            if pi[(s,a)] == 1:\n",
    "                old_a = a\n",
    "        if old_a == None:\n",
    "            old_a = 'nan'\n",
    "        a_given_s = None\n",
    "        m = -1e9\n",
    "        for a in actions:\n",
    "            s_d, r = find(s, a)\n",
    "            if r + gamma*V[s_d] > m:\n",
    "                m = r + gamma*V[s_d]\n",
    "                a_given_s = a\n",
    "                \n",
    "        for a in actions:\n",
    "            pi[(s,a)] = 0\n",
    "\n",
    "        pi[(s,a_given_s)] = 1.0\n",
    "        if a_given_s != old_a:\n",
    "            f = False\n",
    "    return (pi, f)\n",
    "\n",
    "def policy_iteration():\n",
    "    print(\"Policy Iteration:\")\n",
    "    V = {}\n",
    "    states = []\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            s = (i,j)\n",
    "            states.append(s)\n",
    "            V[s] = 0.0\n",
    "\n",
    "    pi = {}\n",
    "    for s in states:\n",
    "        for a in actions:\n",
    "            pi[(s,a)] = 0.25\n",
    "    f = False\n",
    "    iter = 1\n",
    "    while not f:\n",
    "        itr = \"Iteration: \" + str(iter)        \n",
    "        V = policy_eval(V, pi)\n",
    "        pi, f = policy_upd(V, pi)\n",
    "        show(V, pi, itr)\n",
    "        iter += 1\n",
    "    return (V, pi)\n",
    "\n",
    "V, pi = value_iteration()\n",
    "print()\n",
    "V_d, pi_d = policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal (Value Iteration):\n",
      "[0.0, -1.0, -2.0, -3.0]\n",
      "[-1.0, -2.0, -3.0, -2.0]\n",
      "[-2.0, -3.0, -2.0, -1.0]\n",
      "[-3.0, -2.0, -1.0, 0.0]\n",
      "\n",
      "['.', 'left', 'left', 'down']\n",
      "['up', 'up', 'up', 'down']\n",
      "['up', 'up', 'down', 'down']\n",
      "['up', 'right', 'right', '.']\n",
      "\n",
      "Optimal (Policy Iteration):\n",
      "[0.0, -1.0, -2.0, -3.0]\n",
      "[-1.0, -2.0, -3.0, -2.0]\n",
      "[-2.0, -3.0, -2.0, -1.0]\n",
      "[-3.0, -2.0, -1.0, 0.0]\n",
      "\n",
      "['.', 'left', 'left', 'down']\n",
      "['up', 'up', 'up', 'down']\n",
      "['up', 'up', 'down', 'down']\n",
      "['up', 'right', 'right', '.']\n"
     ]
    }
   ],
   "source": [
    "show(V, pi, \"Optimal (Value Iteration):\")\n",
    "print()\n",
    "show(V_d, pi_d, \"Optimal (Policy Iteration):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import random\n",
    "MAXN = 20\n",
    "rent = 10\n",
    "transport = -2\n",
    "la_rental = 3\n",
    "lb_rental = 4\n",
    "la_return = 3\n",
    "lb_return = 2\n",
    "gamma = 0.9\n",
    "\n",
    "fac = [1]*51\n",
    "for i in range(1,51):\n",
    "    fac[i] = fac[i-1]*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison(x, l):\n",
    "    return round(exp(-l)*pow(l,x)/fac[x], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(s, s_d, a):\n",
    "    sa = s[0]\n",
    "    sb = s[1]\n",
    "    sa_d = s_d[0]\n",
    "    sb_d = s_d[1]\n",
    "    \n",
    "    if sa_d > 20 or sb_d > 20 or sa > 20 or sb > 20:\n",
    "        return [0, 0]\n",
    "    \n",
    "    if sa_d < 0 or sb_d < 0 or sa < 0 or sb < 0:\n",
    "        return [0, 0]\n",
    "        \n",
    "    da = sa_d - sa\n",
    "    db = sb_d - sb\n",
    "\n",
    "    if sa - a > MAXN or sb + a > MAXN:\n",
    "        return [0, 0]\n",
    "    \n",
    "    reward_in_a, reward_in_b = 0, 0\n",
    "    pa, pb = 0.0, 0.0\n",
    "    maxa = sa - a\n",
    "    maxb = sb + a\n",
    "    \n",
    "    if maxa > 20 or maxb > 20:\n",
    "        return [0, 0]\n",
    "    \n",
    "    for rent_in_a in range(maxa, -1, -1):\n",
    "        return_in_a = da + rent_in_a + a\n",
    "        if return_in_a < 0:\n",
    "            continue\n",
    "        p = poison(return_in_a, la_return)*poison(rent_in_a, la_rental)\n",
    "        reward_in_a = reward_in_a + (rent_in_a*rent*p)\n",
    "        pa += p\n",
    "    \n",
    "    for rent_in_b in range(maxb, -1, -1):\n",
    "        return_in_b = db + rent_in_b - a\n",
    "        if return_in_b < 0:\n",
    "            continue\n",
    "        p = poison(return_in_b, lb_return)*poison(rent_in_b, lb_rental)\n",
    "        reward_in_b = reward_in_b + (rent_in_b*rent*p)\n",
    "        pb += p\n",
    "        \n",
    "    r_park = 0\n",
    "    if sa - a > 10:\n",
    "        r_park = -4\n",
    "    if sb + a > 10:\n",
    "        r_park += -4\n",
    "        \n",
    "    if a>0:\n",
    "        a -= 1\n",
    "    total_reward = reward_in_a + reward_in_b + (abs(a)*transport)\n",
    "    total_prob = pa*pb\n",
    "    if total_prob > 1:\n",
    "        print(\"Error\")\n",
    "        return 0,0\n",
    "    return [total_prob, total_reward]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_val(V):\n",
    "    rewards = [[0 for i in range(21)] for j in range(21)]\n",
    "    for i in V:\n",
    "        x, y = i\n",
    "        rewards[x][y] = V[i]\n",
    "    for i in range(21):\n",
    "        print(rewards[i])\n",
    "    return rewards\n",
    "\n",
    "def E(s, V, pi):\n",
    "    v = 0\n",
    "    for s_d in states:\n",
    "        p, r = get_prob(s, s_d , pi[s])\n",
    "        v = v + (p*(r + gamma*V[s_d]))\n",
    "    return v\n",
    "\n",
    "epsilon = 0.01\n",
    "\n",
    "def policy_eval(V, pi):\n",
    "    print(\"Policy Evaluation\")\n",
    "    iter = 0\n",
    "    Vd = {}\n",
    "    while True:\n",
    "        iter+=1\n",
    "        print(\"Sub-Iter:\", iter)    \n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            Vd[s] = V[s]\n",
    "        for s in states:\n",
    "            v = Vd[s]\n",
    "            V[s] = E(s,Vd,pi)\n",
    "            delta = max(delta, abs(v-V[s]))\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "        for s in states:\n",
    "            Vd[s] = V[s]\n",
    "    return V\n",
    "\n",
    "def policy_upd(V, pi):\n",
    "    print(\"Policy Update\")\n",
    "    f = True\n",
    "    for s in states:\n",
    "        old_a = pi[s]\n",
    "        a_given_s = None\n",
    "        m = -1e9\n",
    "        for a in actions:\n",
    "            for s_d in states:\n",
    "                p, r = get_prob(s, s_d, a)\n",
    "                if p*(r + gamma*V[s_d]) > m:\n",
    "                    m = p*(r + gamma*V[s_d])\n",
    "                    a_given_s = a\n",
    "        pi[s] = a_given_s\n",
    "        if a_given_s != old_a:\n",
    "            f = False\n",
    "    return (pi, f)\n",
    "\n",
    "def display_policy(pi):\n",
    "    r = [[0 for i in range(21)] for j in range(21)]\n",
    "    for s in states:\n",
    "        r[s[0]][s[1]] = pi[s]\n",
    "    r = np.array(r)\n",
    "    print(r)\n",
    "    return r\n",
    "\n",
    "def policy_iteration(V, pi):\n",
    "    f = False\n",
    "    iter = 1\n",
    "    while not f and iter<=4:\n",
    "        print(\"Iteration:\",iter)\n",
    "        V = policy_eval(V, pi)\n",
    "        pi, f = policy_upd(V, pi)\n",
    "        display_policy(pi)\n",
    "        iter += 1\n",
    "    return (V, pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Policy Evaluation\n",
      "Sub-Iter: 1\n",
      "Sub-Iter: 2\n",
      "Sub-Iter: 3\n",
      "Sub-Iter: 4\n",
      "Sub-Iter: 5\n",
      "Sub-Iter: 6\n",
      "Sub-Iter: 7\n",
      "Sub-Iter: 8\n",
      "Sub-Iter: 9\n",
      "Sub-Iter: 10\n",
      "Sub-Iter: 11\n",
      "Sub-Iter: 12\n",
      "Sub-Iter: 13\n",
      "Sub-Iter: 14\n",
      "Sub-Iter: 15\n",
      "Sub-Iter: 16\n",
      "Sub-Iter: 17\n",
      "Sub-Iter: 18\n",
      "Policy Update\n",
      "[[ 0  0  0  0 -1 -1 -1 -2 -2 -3 -3 -3 -4 -4 -4 -4 -4 -5 -5 -5 -5]\n",
      " [ 1  0  0  0  0 -1 -1 -2 -2 -2 -2 -3 -3 -3 -3 -3 -4 -4 -4 -5 -5]\n",
      " [ 1  1  0  0  0  0 -1 -1 -1 -1 -2 -2 -2 -2 -3 -3 -3 -3 -4 -4 -4]\n",
      " [ 1  1  1  1  0  0  0  0 -1 -1 -1 -1 -2 -2 -2 -2 -2 -3 -3 -3 -3]\n",
      " [ 1  1  1  1  1  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -2 -2 -2 -2 -2]\n",
      " [ 2  2  1  1  1  1  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1]\n",
      " [ 2  2  2  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 3  3  2  2  2  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  3  3  3  2  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0]\n",
      " [ 4  4  4  3  3  2  2  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  4  4  3  3  2  2  1  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  5  4  4  3  3  2  2  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  5  5  4  4  3  3  2  2  1  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  5  5  5  4  4  3  3  2  2  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  5  5  5  5  4  4  3  3  2  2  2  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  5  5  5  5  5  4  4  3  3  3  2  2  2  1  1  1  1  1  0]\n",
      " [ 5  5  5  5  5  5  5  5  4  4  4  3  3  3  2  2  2  1  1  1  0]\n",
      " [ 5  5  5  5  5  5  5  5  5  5  4  4  4  3  3  3  2  2  1  1  0]\n",
      " [ 5  5  5  5  5  5  5  5  5  5  5  5  4  4  4  3  3  2  2  1  0]\n",
      " [ 5  5  5  5  5  5  5  5  5  5  5  5  5  5  4  4  3  3  2  1  0]\n",
      " [ 5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  4  4  3  2  1  0]]\n",
      "Iteration: 2\n",
      "Policy Evaluation\n",
      "Sub-Iter: 1\n",
      "Sub-Iter: 2\n",
      "Sub-Iter: 3\n",
      "Sub-Iter: 4\n",
      "Sub-Iter: 5\n",
      "Sub-Iter: 6\n",
      "Sub-Iter: 7\n",
      "Sub-Iter: 8\n",
      "Sub-Iter: 9\n",
      "Sub-Iter: 10\n",
      "Sub-Iter: 11\n",
      "Sub-Iter: 12\n",
      "Sub-Iter: 13\n",
      "Sub-Iter: 14\n",
      "Sub-Iter: 15\n",
      "Sub-Iter: 16\n",
      "Sub-Iter: 17\n",
      "Sub-Iter: 18\n",
      "Sub-Iter: 19\n",
      "Sub-Iter: 20\n",
      "Sub-Iter: 21\n",
      "Sub-Iter: 22\n",
      "Policy Update\n",
      "[[ 0  0  0 -1 -1 -1 -2 -2 -3 -3 -3 -4 -4 -4 -4 -4 -4 -5 -5 -5 -5]\n",
      " [ 1  0  0  0  0 -1 -1 -2 -2 -3 -3 -3 -3 -3 -3 -4 -4 -4 -5 -5 -5]\n",
      " [ 1  1  0  0  0 -1 -1 -1 -2 -2 -2 -2 -2 -3 -3 -3 -3 -4 -4 -4 -4]\n",
      " [ 1  1  1  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -3 -3 -3 -3 -3]\n",
      " [ 1  1  1  1  0  0  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -2 -2]\n",
      " [ 2  2  1  1  1  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 2  2  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 3  3  2  2  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  3  3  2  2  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  4  3  3  2  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  3  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0 -1]\n",
      " [ 5  4  4  3  2  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0]\n",
      " [ 5  5  4  3  3  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0]\n",
      " [ 5  5  4  4  2  2  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  5  3  3  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  4  4  2  2  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      " [ 5  5  5  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  4  4  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  5  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  4  4  3  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  4  3  2  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0]]\n",
      "Iteration: 3\n",
      "Policy Evaluation\n",
      "Sub-Iter: 1\n",
      "Sub-Iter: 2\n",
      "Sub-Iter: 3\n",
      "Sub-Iter: 4\n",
      "Sub-Iter: 5\n",
      "Sub-Iter: 6\n",
      "Sub-Iter: 7\n",
      "Sub-Iter: 8\n",
      "Sub-Iter: 9\n",
      "Sub-Iter: 10\n",
      "Sub-Iter: 11\n",
      "Sub-Iter: 12\n",
      "Sub-Iter: 13\n",
      "Sub-Iter: 14\n",
      "Sub-Iter: 15\n",
      "Sub-Iter: 16\n",
      "Policy Update\n",
      "[[ 0  0  0 -1 -1 -1 -2 -2 -3 -3 -3 -4 -4 -4 -4 -4 -5 -5 -5 -5 -5]\n",
      " [ 1  0  0  0  0 -1 -1 -2 -2 -2 -3 -3 -3 -3 -3 -4 -4 -4 -5 -5 -5]\n",
      " [ 1  1  0  0  0 -1 -1 -1 -2 -2 -2 -2 -2 -3 -3 -3 -3 -4 -4 -4 -4]\n",
      " [ 1  1  1  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -3 -3 -3 -3 -3]\n",
      " [ 1  1  1  1  0  0  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -2 -2]\n",
      " [ 2  2  1  1  1  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 2  2  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 3  3  2  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  3  3  2  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  4  3  2  2  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  3  2  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  4  3  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0]\n",
      " [ 5  5  4  3  2  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0]\n",
      " [ 5  5  4  3  2  2  2  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  4  3  3  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  4  4  2  2  2  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      " [ 5  5  5  3  3  3  1  2  1  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  4  4  4  2  3  2  2  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  5  5  3  4  3  3  2  2  2  2  2  2  1  1  1  1  1  1  0]\n",
      " [ 5  5  4  4  5  4  4  3  3  3  3  3  3  2  2  2  2  1  1  1  0]\n",
      " [ 5  5  5  5  5  5  4  4  4  4  4  4  3  3  3  3  2  2  1  1  0]]\n",
      "Iteration: 4\n",
      "Policy Evaluation\n",
      "Sub-Iter: 1\n",
      "Sub-Iter: 2\n",
      "Sub-Iter: 3\n",
      "Sub-Iter: 4\n",
      "Sub-Iter: 5\n",
      "Sub-Iter: 6\n",
      "Sub-Iter: 7\n",
      "Sub-Iter: 8\n",
      "Sub-Iter: 9\n",
      "Sub-Iter: 10\n",
      "Sub-Iter: 11\n",
      "Sub-Iter: 12\n",
      "Policy Update\n",
      "[[ 0  0  0 -1 -1 -1 -2 -2 -3 -3 -3 -4 -4 -4 -4 -4 -5 -5 -5 -5 -5]\n",
      " [ 1  0  0  0  0 -1 -1 -2 -2 -2 -3 -3 -3 -3 -3 -4 -4 -4 -5 -5 -5]\n",
      " [ 1  1  0  0  0 -1 -1 -1 -2 -2 -2 -2 -2 -3 -3 -3 -3 -4 -4 -4 -4]\n",
      " [ 1  1  1  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -3 -3 -3 -3 -3]\n",
      " [ 1  1  1  1  0  0  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -2 -2]\n",
      " [ 2  2  1  1  1  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 2  2  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 3  3  2  2  1  1  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  3  3  2  1  1  1  1  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  4  3  2  2  1  1  1  1  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  3  2  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  4  3  2  1  1  1  1  1  1  1  1  1  0  0  1  0  0  0  0]\n",
      " [ 5  5  4  3  2  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0]\n",
      " [ 5  5  4  3  3  2  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0]\n",
      " [ 5  5  4  4  3  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  5  4  2  2  2  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      " [ 5  5  5  3  3  3  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      " [ 5  5  4  4  4  2  1  2  1  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  5  3  3  2  3  1  1  1  1  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  4  4  3  4  1  1  1  1  1  1  1  1  1  2  1  1  1  1  0]\n",
      " [ 5  5  5  4  5  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0]]\n"
     ]
    }
   ],
   "source": [
    "states = []\n",
    "pi = {}\n",
    "V = {}\n",
    "actions = [i for i in range(-5,6)]\n",
    "for i in range(MAXN+1):\n",
    "    for j in range(MAXN+1):\n",
    "        V[(i,j)] = random.random()\n",
    "        states.append((i,j))\n",
    "        pi[(i,j)] = 0\n",
    "\n",
    "for s in states:\n",
    "    pi[(s,0)] = 1.0\n",
    "\n",
    "V, pi = policy_iteration(V,pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 -1 -1 -1 -2 -2 -3 -3 -3 -4 -4 -4 -4 -4 -5 -5 -5 -5 -5]\n",
      " [ 1  0  0  0  0 -1 -1 -2 -2 -2 -3 -3 -3 -3 -3 -4 -4 -4 -5 -5 -5]\n",
      " [ 1  1  0  0  0 -1 -1 -1 -2 -2 -2 -2 -2 -3 -3 -3 -3 -4 -4 -4 -4]\n",
      " [ 1  1  1  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -3 -3 -3 -3 -3]\n",
      " [ 1  1  1  1  0  0  0  0  0  0 -1 -1 -1 -1 -1 -2 -2 -2 -2 -2 -2]\n",
      " [ 2  2  1  1  1  0  0  0  0  0  0  0  0  0 -1 -1 -1 -1 -1 -1 -1]\n",
      " [ 2  2  2  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1]\n",
      " [ 3  3  2  2  1  1  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  3  3  2  1  1  1  1  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  4  3  2  2  1  1  1  1  1  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 5  4  3  3  2  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  4  4  3  2  1  1  1  1  1  1  1  1  1  0  0  1  0  0  0  0]\n",
      " [ 5  5  4  3  2  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0]\n",
      " [ 5  5  4  3  3  2  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0]\n",
      " [ 5  5  4  4  3  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0]\n",
      " [ 5  5  5  4  2  2  2  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      " [ 5  5  5  3  3  3  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0]\n",
      " [ 5  5  4  4  4  2  1  2  1  1  1  1  1  1  1  1  1  1  1  0  0]\n",
      " [ 5  5  5  3  3  2  3  1  1  1  1  1  1  1  1  1  1  1  1  1  0]\n",
      " [ 5  5  4  4  3  4  1  1  1  1  1  1  1  1  1  2  1  1  1  1  0]\n",
      " [ 5  5  5  4  5  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0]]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import numpy as np\n",
    "r = display_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sb.heatmap(r, square=True)\n",
    "ax.invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
